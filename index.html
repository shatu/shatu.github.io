<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <!-- Google Analytics tag -- please don't copy! -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-L7DDW61EF8"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-L7DDW61EF8');
    </script>
    <meta name=viewport content=“width=800”>
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <link href='https://fonts.googleapis.com/css?family=Titillium Web' rel='stylesheet'>
    <style type="text/css">
      /* Design Credits: Jon Barron and Abhishek Kar and Saurabh Gupta*/
      a {
      color: #1772d0;
      text-decoration:none;
      }
      a:focus, a:hover {
      color: #f09228;
      text-decoration:none;
      }
      body,td,th {
        font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
        font-size: 16px;
        font-weight: 400
      }
      heading {
        font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
        font-size: 19px;
        font-weight: 1000
      }
      strong {
        font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
        font-size: 16px;
        font-weight: 1200
      }
      strongred {
        font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
        color: 'red' ;
        font-size: 16px
      }
      sectionheading {
        font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
        font-size: 22px;
        font-weight: 600
      }
    </style>
    <style>
      .glow-badge {
        color: black;
        font-size: 0.90em;        /* Slightly smaller to match superscript feel */
        font-weight: 500;         /* Match body text more closely */
        letter-spacing: 0.5px;    /* Adds spacing to counter glow thickness */
        vertical-align: baseline; /* Keeps alignment consistent with text line */
        margin-left: 2px;         /* Moves the text away from the * */
        animation: glowPulse 2s ease-in-out infinite;
      }

      @keyframes glowPulse {
        0%   { text-shadow: 0 0 4px #f6e07f, 0 0 8px #f6e07f; }
        50%  { text-shadow: 0 0 10px #ffe98a, 0 0 18px #ffd74a; }
        100% { text-shadow: 0 0 4px #f6e07f, 0 0 8px #f6e07f; }
      }
    </style>
    <link rel="shortcut icon" type="image/png" href="./images1/ShashankGupta.jpeg" />
    <script type="text/javascript" src="js/hidebib.js"></script>
    <title>Shashank Gupta</title>
    <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
    <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="900" border="0" align="center" cellspacing="0" cellpadding="20">
    <tr>
      <td halign="center">
        <p align="center">
          <font size="6">Shashank Gupta</font>
        </p>
      </td>
    </tr>
    <tr>
      <td>
        <!-- (Start) Top Part -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="70%" valign="middle">
              <p>
                I'm a researcher at the <a href="https://allenai.org/"><strong>Allen Institute for AI (Ai2)</strong></a> in Seattle.
              </p>
              <p>
                Broadly, I am interested in building general-purpose AI agents that can: <br>
                (1) reason about complex problems through natural language rationalization, <br>
                (2) faithfully express their uncertainty in their knowledge and reasoning, and <br>
                (3) continuously improve through self-reflection and human feedback.
              </p>
              <p>
                My current research focus is on AI for Scientific Discovery. I am particularly interested in AI for Math (e.g., Automated Theorem Proving, better foundation models for Math), 
                building agents for finding supporting/contrary evidence from literature, and retrieval-augmented and memory architectures for supporting these use cases.
              </p>
              <p align="center">
                <a href="./data/ShashankGupta-CV.pdf">CV</a> | 
                <a href=mailto:shashank.nlp@gmail.com>E-Mail</a> | 
                <a href="https://scholar.google.com/citations?user=U2Gz-NIAAAAJ&hl=en">Google Scholar</a> | 
                <a href="https://www.semanticscholar.org/author/Shashank-Gupta/2152953535">Semantic Scholar</a> | 
                <a href="https://github.com/shatu">Github</a> | <a href="https://twitter.com/shashank_bits"> Twitter</a>
              </p>
            </td>
            <td width="100%" valign="top">
              <a href="./images1/ShashankGupta.jpeg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="./images1/ShashankGupta.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </table>
        <!-- (End) Top Part -->

        <!-- (Start) Affiliations -->
        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody>
            <tr>
              <td>
                <heading>Affiliations</heading>
              </td>
            </tr>
          </tbody>
        </table>

        <table align="center">
          <tbody>
            <tr>
              <td width="22%" align="center">
                <a href="http://www.iitk.ac.in/" target="_blank">
                <img style="width:80px"  src="unnat_jain_files/iitk.png"></a>&nbsp &nbsp
              </td>
              <td width="22%" align="center">
                <a href="https://www.umass.edu/" target="_blank">
                <img style="width:80px"  src="unnat_jain_files/umass.png"></a>&nbsp &nbsp
              </td>
              <td width="22%" align="center">
                <a href="https://cs.illinois.edu/" target="_blank">
                <img style="width:100px" src="unnat_jain_files/uiuc2.jpg"></a>&nbsp &nbsp
              </td>
              <td width="24%" align="center">
                <a href="https://research.fb.com/category/facebook-ai-research/" target="_blank">
                <img style="width:150px" src="unnat_jain_files/postdoc_2.png"></a>&nbsp &nbsp
              </td>
            </tr>
            <tr>
              <td width="22%" align="center"><font size="2">IIT Kanpur<br>2011-2016</font></td>
              <td width="22%" align="center"><font size="2">UMass Amherst<br>Summer 2015</font></td>
              <td width="22%" align="center"><font size="2">UIUC <br>2016-2022</font></td>
              <td width="22%" align="center"><font size="2">FAIR (collab. w/ CMU) <br>2022-present</font></td>
            </tr>
          </tbody>
        </table> -->
        <!-- (End) Affiliations -->
        
        <!-- <br> -->

        <!-- (Start) Internships -->
        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody>
            <tr>
              <td>
                <heading>Internships</heading>
              </td>
            </tr>
          </tbody>
        </table>

        <table align="center">
          <tbody>
            <tr>
              <td width="23%" align="center">
                <a href="https://www.uber.com/info/atg/" target="_blank">
                <img style="width:120px" src="unnat_jain_files/uber2.png"></a>&nbsp &nbsp
              </td>
              <td width="22%" align="center">
                <a href="https://prior.allenai.org/" target="_blank">
                <img style="width:60px" src="unnat_jain_files/ai2_2.png"></a>&nbsp &nbsp
              </td>
              <td width="24%" align="center">
                <a href="https://research.fb.com/category/facebook-ai-research/" target="_blank">
                <img style="width:150px" src="unnat_jain_files/fair_ut_2.png"></a>&nbsp &nbsp
              </td>
              <td width="27%" align="center">
                <a href="http://deepmind.com/" target="_blank">
                <img style="width:160px" src="unnat_jain_files/deepmind_2.png"></a>&nbsp &nbsp
              </td>
            </tr>
            <tr>
              <td width="24%" align="center"><font size="2">Uber ATG<br>Summer 2017</font></td>
              <td width="24%" align="center"><font size="2">Allen Institute for AI<br>Summer 2018, 2020</font></td>
              <td width="24%" align="center"><font size="2">FAIR (collab w/ UT Austin)<br>Summer 2019, FA19, SP20</font></td>
              <td width="24%" align="center"><font size="2">Google DeepMind<br>Summer 2021, FA21</font></td>
            </tr>
          </tbody>
        </table> -->
        <!-- (End) Internships -->

        <!-- <br> -->

        <!-- (Start) News -->
        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>News</heading>
            </td>
          </tr>
        </table>
	  
        <table class="news-table" width="100%" align="center" border="0"     style="text-align: justify">
          <colgroup><col width="15%">
            <col width="85%">
          </colgroup>
          <tbody>
            <tr>
              <td valign="top" align="center"><strong>Dec 2023</strong></td>
              <td>Organizing the community-building workshop <a href="https://sites.google.com/view/retrocv/">'CV 20/20: A Retrospective Vision'</a> at CVPR 2024.</td>
            </tr>
            <tr>
              <td valign="top" align="center"><strong>Sep 2023</strong></td>
              <td>Serving as Area Chair for CVPR 2024.</td>
            </tr>
            <tr>
              <td valign="top" align="center"><strong>Jun 2023</strong></td>
              <td>Organizing the <a href="https://sites.google.com/view/academic-cv/">'Scholars & Big Models: How Can Academics Adapt?'</a> workshop at CVPR 2023.</td>
            </tr>
            <tr>
              <td valign="top" align="center"><strong>Jan 2023</strong></td>
              <td>Serving as Area Chair for NeurIPS 2023.</td>
            </tr>
            <tr>
              <td valign="top" align="center"><strong>Dec 2022</strong></td>
              <td>Organizing the <a href="https://sites.google.com/view/roboadapt">RoboAdapt Workshop</a> at CoRL 2023.</td>
            </tr>
            <tr>
              <td valign="top" align="center"><strong>Sep 2022</strong></td>
              <td>Serving as Area Chair for CVPR 2023.</td>
            </tr>
            <tr>
              <td valign="top" align="center"><strong>Aug 2022</strong></td>
              <td>In 2022, <a href="https://github.com/HimangiM/RepLAI">RepLAI</a> accepted at NeurIPS, <a href="https://jbwasse2.github.io/portfolio/SLING/">SLING</a> at CoRL, and survey on <a href="https://arxiv.org/pdf/2210.06849">Retrospectives of Embodied AI</a> released.</td>
            </tr>
            <tr>
              <td valign="top" align="center"><strong>Mar 2022</strong></td>
              <td> Started at Meta AI & CMU w/ Abhinav, Deepak, and Xinlei -- diving into embodied learning (from & for humans), representations, and robotics.</td>
            </tr>  
          </tbody>
        </table> -->
        <!-- (End) News -->

        <!-- <a href="javascript:toggleblock('news')">+ older (PhD) news</a> -->

        <!-- (Start) Old news -->
        <!-- <div id="news" style="display:none">
          <table id="news-extra" class="news-table" width="100%" align="center" border="0"     style="text-align: justify">
            <colgroup><col width="15%">
              <col width="85%">
            </colgroup>
            <tbody>
              <tr>
                  <td valign="top" align="center"><strong>Oct 2021</strong></td>
                  <td>In 2021, <a href="https://ioujenliu.github.io/CMAE/">CMAE</a> accepted at ICML, <a href="https://unnat.github.io/gridtopix/">GridToPix</a> & <a href="https://shivanshpatel35.github.io/comon/">CoMON</a> at ICCV, <a href="https://3dlg-hcvc.github.io/LAW-VLNCE">LAW</a> at EMNLP, and <a href="https://unnat.github.io/advisor/">ADVISOR</a> at NeurIPS.</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Jul 2021</strong></td>
                <td>Invited talk on 'Collaborative Embodied Agents' at Visual Geometry Group at University of Oxford. [<a href="files/vgg_talk.pdf">slides</a>] [<a href="https://youtu.be/4Do7xJb9ftc">video</a>]</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Jun 2021</strong></td>
                <td>Awarded <a href="https://cs.illinois.edu/about/awards/graduate-fellowships-awards/cw-gear-outstanding-graduate-student">C. W. Gear Outstanding Graduate Student</a> 2021.</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>May 2021</strong></td>
                <td>Passed preliminary examination. Thanks committee members: <a href="https://www.alexander-schwing.de/">Alex</a>, <a href="http://slazebni.cs.illinois.edu/">Lana</a>, <a href="https://dhoiem.cs.illinois.edu/">Derek</a>, <a href="https://www.cs.utexas.edu/~grauman/">Kristen</a>, and <a href="https://nanjiang.cs.illinois.edu/">Nan</a>. [<a href="https://unnat.github.io/files/prelim_talk.pdf">slides</a>]</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Feb 2021</strong></td>
                <td>Organizing <a href="https://soundspaces.org/challenge">SoundSpaces Challenge</a> and <a href="http://multion-challenge.cs.sfu.ca/">MultiON Challenge</a> at the <a href="https://embodied-ai.org/">Embodied AI Workshop, CVPR 2021</a>.</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Dec 2020</strong></td>
                <td>Awarded '<a href="https://allenai.org/outstanding-interns">AI2 Outstanding Intern of 2020</a>' -- thank you, mentors!</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Oct 2020</strong></td>
                <td>Released NeurIPS 2020 paper on <a href="https://shivanshpatel35.github.io/multi-ON/">Multi-Object Navigation</a> in AIHabitat.</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Oct 2020</strong></td>
                <td>Here is a <a href="https://unnatj.github.io">*spoof* scholar</a> page my friends put together on my birthday in 2020. User discretion advised :p</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Sep 2020</strong></td>
                <td>AllenAct (BETA) has been released -- Check out the <a href="https://allenact.org/">webpage</a> and <a href="https://github.com/allenai/allenact/">github repo</a>.</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Jul 2020</strong></td>
                <td>Talk at <a href="http://datascience.utah.edu/club/sss-2020/unnat-jain">Summer Seminar Series, Utah Center for Data Science</a> on Collaborative Embodied Agents (<a href="https://youtu.be/tyYP3twg1hY">video</a>).</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Jun 2020</strong></td>
                <td><a href="https://unnat.github.io/cordial-sync/">Cordial Sync</a> and <a href="http://vision.cs.utexas.edu/projects/audio_visual_navigation/">SoundSpaces</a> accepted as spotlights to ECCV 2020.</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>May 2020</strong></td>
                <td> Summer #2 at <a href="http://allenai.org/">Allen Institute for Artificial Intelligence</a>, Seattle.</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Dec 2019</strong></td>
                <td>Released <a href="https://arxiv.org/pdf/1912.11474.pdf"> AV Embodied Navigation preprint</a> (intern work at Facebook AI Research).</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Nov 2019</strong></td>
                <td> NeurIPS camera ready, code, and slides for <strong>TAB-VCR</strong> are up on <a href="https://deanplayerljx.github.io/tabvcr/">project page</a>!</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Sep 2019</strong></td>
                <td> <a href="https://www.linkedin.com/in/jingxiang-dean-lin-45ba18126">Jingxiang (Dean) Lin</a>'s <strong>TAB-VCR</strong> accepted at NeurIPS 2019, camera ready coming soon!
              </tr>
              <tr>
                <td valign="top" align="center"><strong>May 2019</strong></td>
                <td> Summer at <a href="https://research.fb.com/category/facebook-ai-research/">Facebook AI Research</a>, Menlo Park.</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Mar 2019</strong></td>
                <td> Named <a href="https://www.qualcomm.com/invention/research/university-relations/innovation-fellowship/2019-north-america">Qualcomm Innovation Fellowship 2019</a> Finalists.</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Feb 2019</strong></td>
                <td> Awarded best presenter at AI session of <a href="https://publish.illinois.edu/cslstudentconference2019/technical-sessions/ai/">CSL student conference 2019</a>.</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Nov 2018</strong></td>
                <td> <a href="https://www.ideals.illinois.edu/bitstream/handle/2142/101574/JAIN-THESIS-2018.pdf?sequence=1&isAllowed=y">MS thesis</a> selected for David J. Kuck outstanding MS thesis award 2019. [<a href="https://cs.illinois.edu/about-us/awards/alumni-awards/top-alumni-and-faculty-honored-their-achievements">CS News</a>]</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>May 2018</strong></td>
                <td> Summer at <a href="http://allenai.org/">Allen Institute for Artificial Intelligence</a>, Seattle.</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Apr 2018</strong></td>
                <td> Accepted UIUC's Ph.D. offer. Will begin fall'18!</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Feb 2017</strong></td>
                <td> <a href="https://arxiv.org/pdf/1803.11186.pdf">Paper</a> on two sided evaluation of visual dialog got accepted to CVPR 2018</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Sep 2017</strong></td>
                <td> Received <a href="http://www.siebelscholars.com/about">Siebel Scholar Award</a> 2017 by Thomas and Stacey Siebel foundation [<a href="https://cs.illinois.edu/news/top-cs-illinois-students-named-2018-siebel-scholars">CS News</a>]</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>May 2017</strong></td>
                <td> Summer at <a href="https://www.uber.com/info/atg/">Uber ATG (self-driving)</a>, Pittsburgh.</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>May 2017</strong></td>
                <td> Received <a href="http://cvpr2017.thecvf.com/files/CVPR_Student_Volunteer.pdf">Student volunteer award</a> from CVF and conference travel grant from UIUC for CVPR 2017.</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Mar 2017</strong></td>
                <td> <a href="https://arxiv.org/pdf/1709.08103.pdf">Paper</a> accepted to Conference on Computer and Robot Vision (CRV) 2017 based on IIT Kanpur's thesis.</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Jan 2017</strong></td>
                <td> <a href="https://arxiv.org/pdf/1704.03493.pdf">Paper</a> accepted at CVPR 2017 as <a href="https://www.youtube.com/watch?v=i8joIhgMiug">spotlight presentation</a>!</td>
              </tr>
              <tr>
                <td valign="top" align="center"><strong>Jul 2016</strong></td>
                <td>Received Director's Gold Medal and Cadence Gold Medal from IIT Kanpur for best all-rounder and best thesis, respectively.</td>
              </tr>
            </tbody>
          </table>
        </div> -->
        <!-- (End) Old news -->

        <!-- (Start) Projects -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Selected Projects</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <!-- OLMo3 -->
          <tr onmouseover="olmo_start()" onmouseout="olmo_stop()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="position:relative; width:100%;">

                <!-- Overlay video (hidden by default, shown on hover) -->
                <div class="two" id="olmo_image"
                    style="
                      position:absolute;
                      top:0;
                      left:0;
                      width:100%;
                      height:100%;
                      opacity:0;
                      transition: opacity 0.3s ease;
                    ">
                  <video id="olmo_video" width="100%" muted autoplay loop playsinline style="display:block;">
                    Your browser does not support the video tag.
                  </video>
                </div>

                <!-- Static image always underneath -->
                <img src="images1/project_overviews/olmo3_vid.png" width="100%" style="display:block;">
              </div>

              <!-- HLS + hover logic -->
              <script src="https://cdn.jsdelivr.net/npm/hls.js@latest"></script>
              <script>
                // --- Set up HLS video from Mux ---
                const video = document.getElementById('olmo_video');
                const hlsSource = 'https://stream.mux.com/952wZavkYIt9UzG1zEul5u5GC01f65sUm.m3u8?redundant_streams=true';

                if (video.canPlayType('application/vnd.apple.mpegurl')) {
                  // Safari has native HLS
                  video.src = hlsSource;
                } else if (window.Hls && Hls.isSupported()) {
                  const hls = new Hls();
                  hls.loadSource(hlsSource);
                  hls.attachMedia(video);
                } else {
                  // Fallback: if nothing else, just set src (may or may not work depending on browser)
                  video.src = hlsSource;
                }

                // --- Hover behavior ---
                function olmo_start() {
                  document.getElementById('olmo_image').style.opacity = '1';
                }

                function olmo_stop() {
                  document.getElementById('olmo_image').style.opacity = '0';
                }

                // Start with video hidden, but already playing underneath
                olmo_stop();
              </script>
            </td>

            <td valign="top" width="65%">
              <p>
                <a href="https://allenai.org/blog/olmo3">
                  <img src="./images1/new.png" alt="[NEW]" width="5%" style="border-style:none;">
                  <heading>OLMo 3</heading>
                </a>
                <br>
                Olmo Team&ast;, Allyson Ettinger, Amanda Bertsch, [...], <strong><u>Shashank&nbsp;Gupta</u></strong>, [...], Noah A. Smith, Hannaneh Hajishirzi
                <br>
                <span class="glow-badge">&ast; Core Contributor</span>
              </p>

              <p>
                <!-- <span style="color:black;">&#x2728; Core Contributor &#x2728;</span><br> -->
                <a href="https://allenai.org/papers/olmo3">paper</a> |
                <a href="https://platform-docs-beta-olmo3.apps.allenai.org/models/olmo3">code</a> |
                <a href="https://huggingface.co/collections/allenai/olmo-3">data & models</a> |
                <!-- <a href="https://huggingface.co/collections/allenai/olmo-3-pre-training">pre-training data</a> |
                <a href="https://huggingface.co/collections/allenai/olmo-3-post-training">post-training data</a> | -->
                <a href="https://allenai.org/blog/olmo3">blog</a> |
                <a href="https://x.com/allen_ai/status/1991507983881379896">X (Twitter)</a>
              </p>
            </td>
          </tr>

          <!-- LLM-SR -->
          <tr>
            <td width="35%">
              <div class="one">
                <div class="two" id='llm_sr'><img src='./images1/project_overviews/llmsr_overview.jpeg' alt="sym" width="100%" style="border-style: none">
                </div>
              </div>
            </td>
            <td valign="top" width="65%">
              <p>
                <a href="https://openreview.net/forum?id=m2nmp8P5in">
                  <heading>LLM-SR: Scientific Equation Discovery via Programming with Large Language Models</heading>
                </a>
                <br>
                Parshin Shojaee, Kazem Meidani, <strong><u>Shashank&nbsp;Gupta</u></strong>, Amir Barati Farimani, Chandan K Reddy
                <!-- <br> -->
              <p>
                <strong>ICLR 2025 (Oral)</strong>
                <br>
                <a href="https://openreview.net/forum?id=m2nmp8P5in">paper</a> | 
                <a href="https://github.com/deep-symbolic-mathematics/llm-sr">code</a> | 
                <a href="https://x.com/ParshinShojaee/status/1791135155790196828">X (Twitter)</a>
              </p>
            </td>
          </tr>

          <!-- SUPER -->
          <tr>
            <td width="35%">
              <div class="one">
                <div class="two" id='super'><img src='./images1/project_overviews/super_overview.png' alt="sym" width="100%" style="border-style: none">
                </div>
              </div>
            </td>
            <td valign="top" width="65%">
              <p>
                <a href="https://arxiv.org/abs/2409.07440">
                  <heading>SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories</heading>
                </a>
                <br>
                Ben Bogin, Kejuan Yang, <strong><u>Shashank&nbsp;Gupta</u></strong>, Kyle Richardson, Erin Bransom, Peter Clark, Ashish Sabharwal, Tushar Khot
                <!-- <br> -->
              <p>
                <strong>EMNLP 2024</strong>
                <br>
                  <span style="color: red;">&#x1F3C6; Outstanding Paper Award &#x1F3C6;</span>
                <br>
                <a href="https://arxiv.org/abs/2409.07440">paper</a> | 
                <a href="https://github.com/allenai/super-benchmark">code</a> | 
                <a href="https://huggingface.co/datasets/allenai/super">dataset</a> | 
                <a href="https://x.com/ben_bogin/status/1835744611836534850">X (Twitter)</a>
              </p>
            </td>
          </tr>

          <!-- AppWorld -->
          <tr>
            <td width="35%">
              <div class="one">
                <div class="two" id='appworld'><img src='./images1/project_overviews/appworld_agent_overview.png' alt="sym" width="100%" style="border-style: none">
                </div>
              </div>
            </td>
            <td valign="top" width="65%">
              <p>
                <a href="https://arxiv.org/abs/2407.18901">
                  <heading>AppWorld: A Controllable World of Apps and People for Benchmarking Interactive Coding Agents</heading>
                </a>
                <br>
                Harsh Trivedi, Tushar Khot, Mareike Hartmann, [...], <strong><u>Shashank&nbsp;Gupta</u></strong>, Ashish Sabharwal, Niranjan Balasubramanian
                <!-- <br> -->
                <p>
                  <strong>ACL 2024</strong>
                  <br>
                    <span style="color: red;">&#x1F3C6; Best Resource Paper Award &#x1F3C6;</span>
                  <br>
                  <a href="https://arxiv.org/abs/2407.18901">paper</a> | 
                  <a href="https://appworld.dev/">website</a> | 
                  <a href="https://github.com/stonybrooknlp/appworld/">code</a> | 
                  <a href="https://appworld.dev/video">video</a> |
                  <a href="https://appworld.dev/poster.pdf">poster</a> |
                  <a href="https://twitter.com/shashank_bits/status/1818702948597403729">X (Twitter)</a>
                </p>
            </td>
          </tr>

          <!-- Persona Bias -->
          <tr>
            <td width="35%">
              <div class="one">
                <div class="two" id='persona_bias'><img src='./images1/project_overviews/persona_bias_animation.gif' alt="sym" width="100%" style="border-style: none"></div>
              </div>
            </td>
            <td valign="top" width="65%">
              <p>
                <a href="https://allenai.github.io/persona-bias/">
                  <heading>Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs</heading>
                </a>
                <br>
                <strong><u>Shashank&nbsp;Gupta</u></strong>, Vaishnavi Shrivastava, Ameet Deshpande, Ashwin Kalyan, Peter Clark, Ashish Sabharwal, Tushar Khot
                <!-- <br> -->
                <p>
                  <strong>ICLR 2024</strong>
                  <br>
                  <a href="https://arxiv.org/abs/2311.04892">paper</a> | 
                  <a href="https://allenai.github.io/persona-bias/">website</a> |
                  <a href="https://github.com/allenai/persona-bias">code</a> |
                  <a href="https://iclr.cc/media/PosterPDFs/ICLR%202024/17986.png">poster</a> |
                  <a href="https://huggingface.co/datasets/allenai/persona-bias">data</a> |
                  <a href="https://twitter.com/shashank_bits/status/1754901849189265703">X (Twitter)</a>
                </p>
            </td>
          </tr>

          <!-- Self-Refine -->
          <tr>
            <td width="35%">
              <div class="one">
                <div class="two" id='self_refine'><img src='./images1/project_overviews/self_refine_loop.gif' alt="sym" width="100%" style="border-style: none"></div>
              </div>
            </td>
            <td valign="top" width="65%">
              <p>
                <a href="https://selfrefine.info/">
                  <heading>Self-Refine: Iterative Refinement with Self-Feedback
                  </heading>
                </a>
                <br>
                Aman Madaan, Niket Tandon, [...], <strong><u>Shashank&nbsp;Gupta</u></strong>, [...], Peter Clark
                <!-- <br> -->
                <p>
                  <strong>NeurIPS 2023</strong><br>
                  <a href="https://arxiv.org/abs/2303.17651">paper</a> | 
                  <a href="https://selfrefine.info/">website</a> |
                  <a href="https://github.com/madaan/self-refine">code</a> |
                  <a href="https://neurips.cc/media/neurips-2023/Slides/71632.pdf">poster</a> |
                  <a href="https://www.forbes.com/sites/lanceeliot/2023/08/30/prompt-engineering-boosted-via-are-you-sure-ai-self-reflective-self-improvement-techniques-that-greatly-improve-generative-ai-answers/?sh=635c99ed3c8e">
                    Forbes
                    <!-- <img src="./images1/media/forbes-logo.jpeg" alt="media logo" height="15" style="border:1px solid #D3D3D3;" hspace="0"> -->
                  </a>
              </p>
            </td>
          </tr>

          <!-- Sparse MoE -->
          <tr>
            <td width="35%">
              <div class="one">
                <div class="two" id ='mt-tag'><img src='./images1/project_overviews/mt-tag_overview.png' alt="sym" width="100%" style="border-style: none">
                </div>
              </div>
            </td>
            <td valign="top" width="65%">
              <p>
                <a href="https://arxiv.org/abs/2204.07689">
                  <heading>
                    Sparsely Activated Mixture-of-Experts are Robust Multi-Task Learners
                  </heading>
                </a>
                <br>
                
                <strong><u>Shashank&nbsp;Gupta</u></strong>, Subhabrata Mukherjee, Krishan Subudhi, Eduardo Gonzalez, Damien Jose, Ahmed H. Awadallah, Jianfeng Gao
                <!-- <br> -->
                <p>
                  <strong>Microsoft AI Journal, 2022</strong><br>
                  <a href="https://arxiv.org/abs/2204.07689">paper</a>
                </p>
            </td>
          </tr>

          <!-- KID -->
          <tr>
            <td width="35%">
              <div class="one">
                <div class="two" id ='kid'><img src='./images1/project_overviews/kid_overview.png' alt="sym" width="100%" style="border-style: none">
                </div>
              </div>
            </td>
            <td valign="top" width="65%">
              <p>
                <a href="https://arxiv.org/abs/2204.03084">
                  <heading>
                    Knowledge Infused Decoding
                  </heading>
                </a>
                <br>
                <p>
                Ruibo Liu, Guoqing Zheng, <strong><u>Shashank&nbsp;Gupta</u></strong>, Radhika Gaonkar, Chongyang Gao, Soroush Vosoughi, Milad Shokouhi, Ahmed Hassan Awadallah
                <!-- <br> -->
                <p>
                  <strong>ICLR 2022</strong><br>
                  <a href="https://arxiv.org/abs/2204.03084">paper</a> |
                  <a href="https://github.com/microsoft/KID">code</a>
                </p>
                <!-- <p>
                  Short Description
                </p> -->
            </td>
          </tr>

          <!-- Efficient Transformers -->
          <tr>
            <td width="35%">
              <div class="one">
                <div class="two" id = 'smartreply'><img src='./images1/project_overviews/efficient_smartreply_overview.png' alt="sym" width="100%" style="border-style: none"></div>
              </div>
            </td>
            <td valign="top" width="65%">
              <p>
                <a href="https://arxiv.org/abs/2111.13999">
                  <heading>Exploring Low-Cost Transformer Model Compression for Large-Scale Commercial Reply Suggestions
                  </heading>
                </a>
                <br>
                Vaishnavi Shrivastava<strong><sup>*</sup></strong>, Radhika Gaonkar<strong><sup>*</sup></strong>, <strong><u>Shashank&nbsp;Gupta</u><sup>*</sup></strong>, Abhishek Jha
                <!-- <br> -->
                <p>
                  <small><strong>*</strong>equal contribution</small>
                  <br>
                  <strong>Microsoft AI Journal, 2021</strong><br>
                  <a href="https://arxiv.org/abs/2111.13999">paper</a> | 
                  <a href="https://www.microsoft.com/en-us/research/group/msai/articles/assistive-ai-makes-replying-easier-2/">blog post</a>
                  <!-- <p>
                    We study low-cost methods to compress Transformer bi-encoder based reply suggestion system, reducing training and inference times by 42% and 35% respectively. We investigate how dataset size, pre-trained model use, and domain adaptation of the pre-trained model affected the performance of compression techniques.
                  </p> -->
                </p>
            </td>
          </tr>
          <!-- Cogcomp-NLP-->
          <tr>
            <td width="35%">
              <div class="one">
                <div class="two" id = 'cogcomp-nlp'><img src='./images1/project_overviews/cogcomp-nlp_overview.png' alt="sym" width="100%" style="border-style: none">
                </div>
              </div>
            </td>
            <td valign="top" width="65%">
              <p>
                <a href="https://github.com/CogComp/cogcomp-nlp">
                  <heading>CogCompNLP: Your Swiss Army Knife for NLP
                  </heading>
                </a>
                <br>
                Daniel Khashabi, Mark Sammons, [...], <strong><u>Shashank&nbsp;Gupta</u></strong>, [...], Dan Roth
                <!-- <br> -->
                <p>
                  <strong>LREC 2018</strong><br>
                  <a href="https://aclanthology.org/L18-1086/">paper</a> |
                  <a href="https://github.com/CogComp/cogcomp-nlp">code</a>
                </p>
            </td>
          </tr>

          <!-- HiPC -->
          <tr>
            <td width="35%">
              <div class="one">
                <div class="two" id ='hipc'><img src='./images1/project_overviews/hipc_overview.gif' alt="sym" width="100%" style="border-style: none"></div>
              </div>
            </td>
            <td valign="top" width="65%">
              <p>
                <a href="./data/papers/Web-scale_Entity_Annotation_Using_MapReduce.pdf">
                  <heading>Web-scale entity annotation using MapReduce
                  </heading>
                </a>
                <br>
                <strong><u>Shashank&nbsp;Gupta</u></strong>, Varun Chandramouli, Soumen Chakrabarti
                <!-- <br> -->
                <p>
                  <strong>HiPC 2013</strong><br>
                  <a href="./papers/Web-scale_Entity_Annotation_Using_MapReduce.pdf">paper</a> |
                  <a href="https://docs.google.com/presentation/d/11v4XOojXYZd3_9srPsXQc1em779ilMIZymXea59iLhE/edit?usp=sharing">slides</a>
                </p>
            </td>
          </tr>
        </table>
        <!-- (End) Projects -->

        <!-- <table width="100%" align="center" border="0" cellpadding="20">-->
            <!--<tr>-->
              <!--<td width="25%"><img src="ta.jpg" alt="numerical" width="160" height="160"></td>-->
              <!--<td width="75%" valign="center">-->
              <!--<p>-->
                <!--<a href="https://relate.cs.illinois.edu/course/cs357-f16/">-->
                <!--<papertitle>CS357 - Numerical Methods - Fall 2016 </papertitle>-->
                <!--</a>-->
                <!--<br><br>-->
                <!--<a href="https://go.illinois.edu/cs101">-->
                <!--<papertitle>CS101 - Intro to Computing - Spring 2016, Fall 2017 </papertitle>-->
                <!--</a>-->
                <!--<br>-->
              <!--</p>-->
              <!--</td>-->
            <!--</tr>-->
        <!--</table> -->

        <!--<table id="thanks" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">-->
            <!--<tr>-->
              <!--<td>-->
                <!--<br>-->
                <!--<p align="right"><font size="2">-->
                  <!--<a href="http://www.cs.berkeley.edu/~barron/">(imitation is the sincerest form of flattery)</a>-->
                  <!--</font>-->
                <!--</p>-->
              <!--</td>-->
            <!--</tr>-->
          <!--</table>-->
        
        <!-- (Start) Credits -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody>
            <tr>
              <td>
                <br>
                <p align="right"><font size="2">
                  Template credits: 
                  <a href="https://unnat.github.io/">Unnat</a>, and
                  <a href="https://jonbarron.info/">Jon</a></font>
                </p>
              </td>
            </tr>
          </tbody>
        </table>
        <!-- (End) Credits -->
      </td>
    </tr>
  </table>
  </body>
</html>