
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
  <meta name="description" content="Shashank is a Masters student with Prof. Dan Roth. His research interests are in Machine Learning and NLP.">
  <meta name="keywords" content="Shashank Gupta, Machine Learning, NLP, Deep Learning, Graduate student, Computer Science, Dan Roth">
  <link rel="icon" href="images/cogcomp.png">

  <title>Shashank Gupta</title>

  <!-- Bootstrap core CSS -->
  <link href="https://getbootstrap.com/docs/3.3/dist/css/bootstrap.min.css" rel="stylesheet">

  <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
  <link href="https://getbootstrap.com/docs/3.3/assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="navbar-fixed-top.css" rel="stylesheet">

  <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
  <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
  <script src="https://getbootstrap.com/docs/3.3/assets/js/ie-emulation-modes-warning.js"></script>

  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->

  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-57880796-2', 'auto');
    ga('send', 'pageview');
  </script>
</head>

<body>

  <!-- Fixed navbar -->
  <nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="#">Shashank Gupta</a>
      </div>
      <div id="navbar" class="navbar-collapse collapse">
        <ul class="nav navbar-nav">
          <li class="active"><a href="#">About</a></li>
          <li><a href="#news">News</a></li>
          <li><a href="#pubs">Publications</a></li>
          <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Projects<span class="caret"></span></a>
            <ul class="dropdown-menu">
              <li><a href="#dataless">Unsupervised Text Classification</a></li>
              <li><a href="#textGen">Text Generation</a></li>
              <li><a href="#joint">Joint Learning</a></li>
              <li role="separator" class="divider"></li>
              <li><a href="#mpi">KB Construction</a></li>
              <li><a href="#iitb">Entity Disambiguation</a></li>
              <li><a href="#yahoo">Ad Sciences</a></li>
              <li role="separator" class="divider"></li>
              <li><a href="#bits">Search Personalization</a></li>
              <li><a href="#misc">Misc</a></li>
            </ul>
          </li>
          <li><a href="#cv">CV</a></li>
          <li><a href="#contact">Contact</a></li>
          <li><a href="#resources">Resources</a></li>
        </ul>
        <!--
        <ul class="nav navbar-nav navbar-right">
          <li class="active"><a href="">Shashank Gupta <span class="sr-only">(current)</span></a></li>
        </ul>
      -->
      </div><!--/.nav-collapse -->
    </div>
  </nav>

    <div class="container">
        <div class="well">
        <table style="border-spacing: 15px;border-collapse: separate;">
          <tbody>
            <tr>
              <td valign="top" margin-top="10px" style="font-size: 0pt;">
              <span style="font-size: 15px">
              <p>
              </br>
              </br>
              <hr style="width: 100%; color: black; height: 1px; background-color:black;" />
              <hr style="width: 100%; color: black; height: 1px; background-color:black;" />
              <h4 style="margin-top: 0em;color:Tomato">March, 2022: Hi there! Thanks for visiting my personal webpage. Unfortunately, the current page is a bit outdated. New content is coming very soon, so please visit again. :)</h4>
              <hr style="width: 100%; color: black; height: 1px; background-color:black;" />
              <hr style="width: 100%; color: black; height: 1px; background-color:black;" />
              </br>
                I'm <b>Shashank</b>, a Masters student in the Computer Science Department at the <b>
                <a href="https://cs.illinois.edu/">University of Illinois at Urbana-Champaign</a></b>, where I'm working
                with <b><a href="http://www.cis.upenn.edu/~danroth/">Prof. Dan Roth</a></b> as a part of his amazing
                <b><a href="http://cogcomp.org/">CogComp</a></b> research group!
              </br>
              </br>
              In general, I work on the intersection of <b>Machine Learning</b> and <b>Natural Language Processing</b>, however, I'm quite excited about <b>Guided Language Generation</b> tasks (like <i>Dialogue systems</i>, <i>Abstractive Summarization</i>, <i>Question Answering</i>), and learning generic <b>Sentence and Document Embeddings</b>. On the ML side, I am interested in studying <b>Deep Generative</b> and <b>Deep Structured models</b>, and like to think about how to <b>Distribute training and inference</b>, and <b>interpret ML models</b> in general.
            </br>
            </br>
            Currently, my work centers around <b>Zero-Shot Learning for Text Classification</b>, and learning and evaluating useful <b>Document Embeddings</b>.
              <hr style="width: 100%; color: black; height: 1px; background-color:black;" />
                Prior to coming to UIUC, I gained plenty of research experience through several research assistantships, and had the pleasure of being a part of some great research labs. For instance, I spent 9 amazing months working with <b><a href="http://people.mpi-inf.mpg.de/~weikum/">Prof. Gerhard Weikum</a></b> and <b><a href="https://sites.ualberta.ca/~denilson/">Prof. Denilson Barbosa</a></b> on <b>Knowledge-Base Construction</b> at the <b><a href="https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/">Max Planck Institute for Informatics</a></b>.
              <br>
              <br>
                I also had the great pleasure of working closely with <b><a href="https://www.cse.iitb.ac.in/~soumen/">Prof. Soumen Chakrabarti</a></b> on <b><a href="https://www.cse.iitb.ac.in/~soumen/doc/CSAW/">Scalable Entity Search and Disambiguation System</a></b> at <b><a href ="https://www.cse.iitb.ac.in/">IIT-Bombay</a></b>, where I was a Research Assistant for about 1.5 years.
              <hr style="width: 100%; color: black; height: 1px; background-color:black;" />
                I was also fortunate to be a part of the amazing
                <b><a href="https://research.yahoo.com/research-areas/advertising-science">Ad-Prediction team</a></b> at <b>Yahoo Labs</b>, where I worked on some challenging problems in <b>Search and Display Ad-platforms</b>, under the guidance of <b><a href="http://www.pmg.it.usyd.edu.au/">Prof. Sanjay Chawla</a></b> and <b><a href="https://www.cse.iitb.ac.in/~shivaram/">Prof. Shivaram Kalyanakrishnan</a></b>.
              <hr style="width: 100%; color: black; height: 1px; background-color:black;" />
                Before my foray into serious research, I spent some wonderful years at <b><a href="http://www.bits-pilani.ac.in/">BITS - Pilani</a></b>, from where I obtained my Bachelor's degree in Computer Science. I spent most of my time there working on my idea of <b>Client-Side Search Personalization</b>.
              </p>
              </span>
              <p>
              <span style="font-size: 20px">

              </span>
              </p>
              </td>
              <td width="0pct" valign="top">
              </br>
              </br>
                <div><span class="lfloat"><img width="120px" src="images/Gupta_Shashank.jpg" alt="" title="Shashank Gupta"></span></div>
              <hr style="width: 100%; color: black; height: 1px; background-color:black;" />
                <a href="https://github.com/shatu"><img width="20px" src="images/github_favicon.ico" alt="shatu" title="Github"></a>
                <a href="mailto:sgupta96@illinois.edu"><img width="25px" src="images/email.png" alt="sgupta96@illinois.edu" title="Email"> </a>
                <a href="https://twitter.com/shashank_bits"><img width="25px" src="images/twitter_favicon.png" alt="shashank_bits" title="Twitter"></a>
                <a href="https://www.linkedin.com/in/shashank-gupta-5182bb28"> <img width="20px" src="images/linkedin_favicon.ico" alt="shashank-gupta-5182bb28" title="Linkedin"></a>
                <a href="https://www.quora.com/profile/Shashank-Gupta-3"> <img width="20px" src="images/quora_favicon.png" alt="Shashank-Gupta-3" title="Quora"></a>
                <a href="https://www.facebook.com/shatu.bits"> <img width="20px" src="images/facebook_favicon.png" alt="shatu.bits" title="Facebook"></a>
              </td>
            </tr>
          </tbody>
        </table>
        </div>
      </br>

      <div class="well" id="news" style="font-size: 15px">
         <h3 style="margin-top: 0em">News</h3>
          <hr style="margin-top: 0em; width: 100%; color: black; height: 1px; background-color:black;" />
         <ul>
        <li>
          <b>02/2018</b>: Will be joining the Microsoft's A.I. for Office team as a Data Scientist in April, 2018.
        </li>
        <li>
          <b>06/2017</b>: Gave a tutorial on <a href="http://bair.berkeley.edu/blog/2017/06/20/learning-to-reason-with-neural-module-networks/">Modular Networks</a> in our Deep Learning Reading Group.
        </li>
        <li>
          <b>05/2017</b>: Started organizing the Deep Learning <a href="https://lists.cs.illinois.edu/lists/arc/deeplearningdiscussion">Discussion Group</a> at UIUC. Checkout our schedules (<a href="https://goo.gl/uZAdVT">Fall'17</a>, <a href="https://goo.gl/YwKVIj">Summer'17</a>) and <a href="https://goo.gl/ehJChm">reading list</a>.
        </li>
        <li>
           <b>02/2017</b>: Gave a tutorial on GANs in the Deep Learning Special Topics <a href="http://slazebni.cs.illinois.edu/spring17">course</a>. [<a href="talks/lec11_gan.pdf">PDF</a>] [<a href="talks/lec11_gan.pptx">Slides</a>]
        </li>
        <li>
          <b>12/2016</b>: Had an amazing time TA-ing an Introductory course on Machine Learning (<a href="http://l2r.cs.uiuc.edu/~danr/Teaching/CS446">CS446</a>).
        </li>
          <li>
            <b>08/2015</b>: Started school at the University of Illinois at Urbana Champaign as a Masters student; will be guided by Prof. Dan Roth.
          </li>
          <li>
          <b>12/2013</b>: Our paper on <i>Web-Scale Entity Annotation using MapReduce</i> was published at <a href = "http://hipc.org/hipc2013/">HiPC, 2013</a>. [<a href="papers/Web-scale_Entity_Annotation_Using_MapReduce.pdf">PDF</a>]
          </li>
          <li>
          <b>07/2013</b>: Invited Talk on <i>Web-Scale Entity Annotation using MapReduce</i> at the <i>Yahoo <a href="https://www.eventbrite.com/e/yahoo-summer-school-2013-registration-6688943811#">Summer School</a> on Information Retrieval & the Semantic Web</i>. [<a href="talks/HadoopAnnot.ppt">Slides</a>]
          </li>
          <li>
          <b>06/2013</b>: Presented a poster on <i>Web-Scale Entity Disambiguation</i> at the NetApp University Day. [<a href="posters/Web-Scale_Entity_Disambiguation.pdf">PDF</a>]
          </li>
          </ul>
        </div>
      </br>

        <div class="well" id="pubs" style="font-size: 15px">
          <h3 style="margin-top: 0em">Publications</h3>
          <hr style="margin-top: 0em; width: 100%; color: black; height: 1px; background-color:black;" />
         <!--  <h4 id="conf">Preprints</h4>
         <br/>
          <ul>

          </ul>
          <br/> -->
          <!--
          <h4 id="conf">Conferences</h4>
        -->
            <ul>
            <li>
              <b>Shashank Gupta</b>, Varun Chandramouli, <a href="https://www.cse.iitb.ac.in/~soumen/">Soumen Chakrabarti</a>, "Web-scale Entity Annotation Using MapReduce." <a href="http://hipc.org/hipc2013/">HiPC 2013</a>. [<a href="papers/Web-scale_Entity_Annotation_Using_MapReduce.pdf">PDF</a>] [<a href="talks/HadoopAnnot.ppt">Slides</a>]
            </li>
            </ul>
          <!--
          <br/>
          <h4 id="ws">Workshops</h4>
          <ul>
          <li>
          </li>
          </ul>
        -->
        </div>
      </br>

        <div class="well" id="projects" style="font-size: 15px">
          <h3 style="margin-top: 0em">Projects</h3>
          <hr style="margin-top: 0em; width: 100%; color: black; height: 1px; background-color:black;" />
            <h4 id="dataless">Unsupervised Text Classification </h4>
            <ul>
              Most existing Text Classification techniques are supervised in nature, and thus require the end-user to provide supervision for every topic/concept of interest. However, getting ample supervision might not always be possible. Moreover, the supervised learning techniques just treat the target label as an ID in their system, and don't really exploit the semantic meaning of the target label. With the advent of large-scale Knowledge-Bases (KBs), it should be possible now to bypass explicit supervision by exploiting the information in KBs.
            </br>
          </br>

              Towards this goal, we are building up on our previous work on <a href="https://cogcomp.org/page/project_view/6">Dataless Classification</a>, and have experimented with new <a href="https://en.wikipedia.org/wiki/Explicit_semantic_analysis">ESA</a>-style <a href="#entity-emb">entity embeddings</a>. We also <a href="#topic-emb">modified</a> the Word2Vec objective to introduce an explicit notion of topical similarity between words. Realizing the importance of compositionality, we are now in the process of <a href="#one-shot">learning</a> topic-sensitive document embeddings. Our initial <a href="#hier-att">study</a> on existing architectures for text classification demonstrated the importance of using a hierarhical model with hierarchical attention.

          </br>
          </br>

                <u><h4 id="one-shot">One-Shot Topic Classification</u> <i><span style="font-weight:normal;margin-left:0.25em;font-size: 15px">(May, 2017 - Present)</span></i><span style="margin-left:0.50em;font-size: 15px">[<a href="https://github.com/shatu/doc2Concept">Code</a> ... Coming Soon] </h4>
                Aim is to use Wikipedia to learn document representations that can enable one-shot learning of topics.
                <ul>
                  <li>
                    Created a new text classification dataset from Wikipedia where categories are the labels.
                  </li>
                  <li>
                      Densified Wikipedia category graph to tackle sparsity issues in the dataset.
                  </li>
                  <li>
                      Currently, in the process of trying out several neural models on this dataset.
                  </li>
                  <li>
                      In the near future, this trained network will be used for producing document representations, which will then be used alongside a meta-learning algorithm for one-shot topic classification on arbitrary datasets.
                  </li>
              </ul>

            </br>

                <u><h4 id="topic-emb">Injecting Topics into Word Embeddings for Unsupervised Classification</u> <i><span style="font-weight:normal;margin-left:0.25em;font-size: 15px">(January â€“ May, 2017)</span></i><span style="margin-left:0.50em;font-size: 15px">[<a href="https://github.com/shatu/word2Concept">Code</a> ... Coming Soon] </h4>
                Aim was to somehow inject a notion of topical similarity into the word embeddings
                <ul>
                  <li>
                    Augmented the Word2Vec loss with an additional Topical loss.
                  </li>
                  <li>
                    Used Wikipediaâ€™s categorization to provide the topical similarity signal.
                  </li>
                  <li>
                    Used these new embeddings for unsupervised document classification.
                  </li>
                </ul>

            </br>
              <u><h4 id="hier-att">A Study of Neural Models for Text Classification</u> <i><span style="font-weight:normal;margin-left:0.25em;font-size: 15px">(August â€“ December, 2016)</span></i><span style="margin-left:0.50em;font-size: 15px">[<a href="https://github.com/shatu/hier-att">Code</a> ... Coming Soon] </h4>
              Aim was to benchmark several neural models for various document classification tasks (topics, sentiment)
              <ul>
                <li>
                  Coded up the <a href="https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf">hierarchical attention model</a> for document classification.
                </li>
                <li>
                  Carried out an ablation study by removing several components from the model.
                </li>
                <li>
                  Both Hierarchical RNN and Attention components were found to be vital for good performance.
                </li>
              </ul>

              </br>

                <u><h4 id="entity-emb">Unsupervised Document Classification using Semantic Embeddings</u> <i><span style="font-weight:normal;margin-left:0.25em;font-size: 15px">(August, 2015 â€“ July, 2016)</span></i></h4>
                Aim was to automatically label a document collection with user-provided topics without any supervision.
                <ul>
                  <li>
                    Key idea was to represent Topics and Documents with Semantic Embeddings and use nearest-neighbor for classification.
                  </li>
                  <li>
                    Created ESA-style sparse embeddings for Entities.
                  </li>
                  <li>
                    Used composition of Entity and Word embeddings to represent documents.
                  </li>
                  <li>
                    Entity embeddings showed promise in entity similarity tasks.
                  </li>
                </ul>
          </ul>

        </br>

          <h4 id="textGen">Text Generation</h4>
          <ul>
              <u><h4 id="gan-vae-text-generation">Conditional Text Generation</u> <i><span style="font-weight:normal;margin-left:0.25em;font-size: 15px">(January â€“ May, 2017)</span></i><span style="margin-left:0.50em;font-size: 15px">[<a href="https://github.com/shatu/TextGAN">Code</a> ... Coming Soon] </h4>
              Aim was to try out Deep Generative Models for text generation.
              <ul>
                <li>
                  Tried out GANs and VAEs for sentiment-conditioned movie review generation.
                </li>
                <li>
                  Tried both Policy-Gradient and Gumbel-Softmax to make GANs handle discrete outputs.
                </li>
                <li>
                  Used Curriculum Learning and a conditional language model to bootstrap the GANs.
                </li>
                <li>
                  Found both GANs and VAEs difficult to train.
                </li>
                <li>
                  Ultimately, a simple conditional language model was found to have the best performance.
                </li>
              </ul>
          </ul>

        </br>

        <h4 id="joint">Joint Learning</h4>
        <ul>
            <u><h4 id="cs546">Joint NER, RelEx and CoRef using CCMs</u> <i><span style="font-weight:normal;margin-left:0.25em;font-size: 15px">(January â€“ May, 2016)</span></i><span style="margin-left:0.50em;font-size: 15px">[<a href="https://github.com/shatu/Joint-NER-RelEx-Coref">Code</a>] </h4>
            Aim was to develop a joint model for NER, Relation Extraction and Coreference Resolution
            <ul>
              <li>
                Experimented with various off-the-shelf tools to note poor performance.
              </li>
              <li>
                Trained classifiers for each of the tasks using CogComp-SL and CogComp-NLP
              </li>
              <li>
                Developed a pipelined system to couple all the classifiers.
              </li>
            </ul>
        </ul>

      </br>

          <h4 id="mpi">Knowledge-Base Construction</h4>
          <ul>
              <u><h4 id="abstention">Agile NERD for KB-Lifecycle</u> <i><span style="font-weight:normal;margin-left:0.25em;font-size: 15px">(August, 2014 â€“ April, 2015)</span></i></h4>
              Aim was to develop a single system capable of Entity Disambiguation (NERD) and Automatic KB Construction.
              <ul>
                <li>
                  Promise being two-fold â€“ automated construction of a real-time canonicalized KB, along with an iterative annotation of emerging entities on corpus.
                </li>
                <li>
                  Worked on differentiating mentions of emerging entities from mentions where NERD should abstain from linking due to insufficient confidence.
                </li>
                <li>
                  Used the disagreement between an ensemble of annotators to signal abstention on a given mention.
                </li>
                <li>
                  Preliminary experiments showed promise in identifying mentions worthy of abstention.
                </li>
              </ul>
          </ul>

        </br>

          <h4 id="iitb">Named Entity Disambiguation</h4>
          <ul>
              <u><h4 id="calibration">Effect of Annotation Quality on Entity Ranking Accuracy</u> <i><span style="font-weight:normal;margin-left:0.25em;font-size: 15px">(June, 2013 â€“ June, 2014)</span></i></h4>
              Developed a scalable NERD system that can annotate entities with calibrated confidence scores
              <ul>
                <li>
                  Aim was to annotate entities on a web-scale corpus with calibrated scores, so as to be able to design robust entity ranking techniques.
                </li>
                <li>
                  Developed a distributed load-balanced framework for training millions of Logistic Regression models.
                </li>
                <li>
                  Also developed scalable solutions for storage and retrieval of these models, so as to be able to quickly annotate and stream through a web-scale corpus.
                </li>
              </ul>

            </br>

              <u><h4 id="benchmarking">NERD Annotation Accuracy Improvement</u> <i><span style="font-weight:normal;margin-left:0.25em;font-size: 15px">(October, 2013 â€“ June, 2014)</span></i></h4>
              Re-designed NERD system to improve F1 by ~30%, and Recall by ~100%, without affecting scalability
              <ul>
                <li>
                  Improved Recall by optimizing Wikipedia parsing to extract more training data.
                </li>
                <li>
                  Benchmarked our system against other annotators on standard datasets.
                </li>
                <li>
                  Engineered features to improve the F1 score.
                </li>
              </ul>

            </br>

              <u><h4 id="hipc">Web-Scale Entity Annotation Using MapReduce</u> <i><span style="font-weight:normal;margin-left:0.25em;font-size: 15px">(January â€“ May, 2013)</span></i></h4>
              Designed a scalable entity annotation and indexing framework in Hadoop.
              <ul>
                <li>
                  Developed a MapReduce implementation for web-scale Entity Disambiguation.
                </li>
                <li>
                  Designed custom-key partitioning strategies to mitigate the load-skew problem of a simple MapReduce implementation.
                </li>
                <li>
                  Improved performance (time to completion) by over 5.4 times.
                </li>
                <li>
                  Published this work in High Performance Computing (HiPC), 2013.
                </li>
                <li>
                  This framework enabled us to annotate and index a web-scale corpus in a reasonable amount of time.
                </li>
              </ul>
          </ul>

        </br>

          <h4 id="yahoo">Ad Sciences</h4>
          <ul>
              <u><h4 id="labs">User Response Prediction for Non-Guaranteed Display Ad Delivery</u> <i><span style="font-weight:normal;margin-left:0.25em;font-size: 15px">(June â€“ December, 2012)</span></i></h4>
              Improved the accuracy of the user-click prediction model.
              <ul>
                <li>
                  Analyzed the entire Display Advertising Exchange platform (Right Media Exchange).
                </li>
                <li>
                  Exploited domain expertise for mining new features.
                </li>
                <li>
                  Crunched Petabytes of data to analyze coverage and signal of each feature.
                </li>
                <li>
                  Showed promise for the approach of training different models for different partitions of training data, by identifying one promising data-partitioning strategy.
                </li>
              </ul>

            </br>

              <u><h4 id="uda">CampOps â€“ Automated Campaign Optimization for Search Advertising</u> <i><span style="font-weight:normal;margin-left:0.25em;font-size: 15px">(January â€“ June, 2012)</span></i></h4>
              Prototyped a tool to automate advertiserâ€™s accountsâ€™ optimization
              <ul>
                <li>
                  Analyzed the entire Sponsored Search Analytics Platform and noticed serious bottlenecks.
                </li>
                <li>
                  As a result, prototyped a tool that:
                  <ul>
                    <li>
                      predicted number of Impressions, Clicks, Conversions and the Amount Charged for each combination of targeting attributes by learning from competitors using machine learning techniques.
                    </li>
                    <li>
                      determined competitors algorithmically by forming a relationship graph between search terms and running community detection algorithms to cluster them, where each cluster roughly maps to one product in the market.
                    </li>
                    <li>
                      provided better keyword suggestions to the advertisers.
                    </li>
                    <li>
                      converted the entire problem of automating advertiserâ€™s accountsâ€™ optimization into a mere Resource Allocation Problem.
                    </li>
                    <li>
                      was expected to generate huge amount of revenue for the company and better ROI for advertisers.
                    </li>
                    <li>
                      was capable of automating and improving the entire work carried out by a dedicated team of Analysts.
                    </li>
                  </ul>
                </li>
              </ul>
          </ul>

        </br>

          <h4 id="bits">Client-side Search Personalization</h4>
          <ul>
              <u><h4 id="mozilla">User Profiling on the Client-side</u> <i><span style="font-weight:normal;margin-left:0.25em;font-size: 15px">(August, 2010 â€“ December, 2011)</span></i></h4>
              Prototyped a browser extension to model user intention and re-rank search results on the client-side.
              <ul>
                <li>
                  Extension recorded client-side exclusive browsing features like tab-switching, browser minimization, text-selection, downloads, number of open tabs, depth/breadth-vise click chain.
                </li>
                <li>
                  Used Neural Networks along with Google Site Search for the supervised learning of the relation of these features with the interest of a user in a webpage.
                </li>
                <li>
                  Created user profile from the pages thus determined to be relevant.
                </li>
                <li>
                  Then used this profile to personalize search results using User Interest Hierarchy (UIH).
                </li>
                <li>
                  Overall, motivated the usefulness of client-side browsing features in personalization of search results.
                </li>
              </ul>
          </ul>

        </br>

          <h4 id="misc">Miscellaneous</h4>
          <ul>
              <u><h4 id="wipro">Online Comprehensive Examination Software</u> <i><span style="font-weight:normal;margin-left:0.25em;font-size: 15px">(May â€“ July, 2010)</span></i></h4>
              Developed a J2EE software for subjective online examinations.
              <ul>
                <li>
                  Aim was to minimize the wastage of paper in carrying out the subjective examinations.
                </li>
                <li>
                  Through this software, the entire academics of the institution (including exams) was made online.
                </li>
              </ul>
          </ul>

        </div>

</br>

<div class="well" id="cv" style="font-size: 15px">
        <h3 id="cv" style="margin-top: 0em">CV</h3>
        <hr style="margin-top: 0em; width: 100%; color: black; height: 1px; background-color:black;" />
        Here's my <a href="cv/Shashank_Gupta_CV.pdf">CV</a>.
</div>

</br>

<div class="well" id="contact" style="font-size: 15px">
        <h3 id="contact" style="margin-top: 0em">Contact</h3>
        <hr style="margin-top: 0em; width: 100%; color: black; height: 1px; background-color:black;" />
        <ul>
          <li>
          <b>Email</b>: shagup@microsoft.com
        </li>
        <li>
          <b>Cell:</b> (+1) 217-904-6006
        </li>
        <li>
            <a href="https://github.com/shatu">Github</a>,
            <a href="https://twitter.com/shashank_bits"> Twitter</a>,
            <a href="https://www.linkedin.com/in/shashank-gupta-5182bb28"> Linkedin</a>,
            <a href="https://www.quora.com/profile/Shashank-Gupta-3"> Quora</a>,
            <a href="https://www.facebook.com/shatu.bits"> Facebook</a>
        </li>
      </ul>
</div>

</br>

<div class="well" id="resources" style="font-size: 15px">
        <h3 style="margin-top: 0em">Resources</h3>
        <hr style="margin-top: 0em; width: 100%; color: black; height: 1px; background-color:black;" />
        I spend countless hours following fellow researchers on social media, and have learnt a great deal from their blogs, mailing lists, reading lists, tweets, podcasts, courses etc. Following is a feeble attempt at showing my gratitude and paying it forward by compiling a list of some useful resources.

      </br>
      </br>

        <b>Blogs</b>
        <ul>
          <li>
            OpenAI's <a href="https://blog.openai.com/">blog</a>
          </li>
          <li>
            Karpathy's <a href="http://karpathy.github.io/">blog</a>
          </li>
          <li>
            <a href="https://twitter.com/hardmaru">David Ha's</a> awesome <a href="http://blog.otoro.net/">blog</a>.
          </li>
          <li>
            <a href="https://twitter.com/ch402">Chris Olah's</a> <a href="http://colah.github.io/">blog</a>
          </li>
          <li>
            <a href="https://distill.pub/">Distill.pub</a>
          </li>
          <li>
            UC Berkeley AI group's <a href="http://bair.berkeley.edu/blog">blog</a>
          </li>
          <li>
            Denny Britz's <a href="http://www.wildml.com/">blog</a>
          </li>
          <li>
            Arthur's awesome <a href="https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0">series</a> on Reinforcement Learning.
          </li>
          <li>
            Sebastian's NLP <a href="http://ruder.io/#open">blog</a>
          </li>
          <li>
            Prof. <a href="http://www.cs.princeton.edu/~arora/">Sanjeev Arora's</a> <a href="http://www.offconvex.org/">blog</a>
          </li>
          <li>
            Prof. <a href="https://www.umiacs.umd.edu/~hal/">Hal Daume's</a> NLP <a href="https://nlpers.blogspot.com/">blog</a>
          </li>
        </ul>
        <b>Newsletters</b>
        <ul>
          <li>
            Jack's Import AI <a href="https://jack-clark.net/">Newsletter</a>
          </li>
          <li>
            Denny's <a href="https://www.getrevue.co/profile/wildml">"The wild week in AI"</a>
          </li>
          <li>
            Sebastian's NLP <a href="http://newsletter.ruder.io/">News</a>
          </li>
        </ul>
        <b>Twitter</b>
        <ul>
            A lot of NLP and Deep Learning researchers are on Twitter, and very actively discuss new and interesting papers. Thanks to <a href="http://www.jasonbaldridge.com/">Prof. Jason Baldridge</a>, we now have a nearly exhaustive <a href="https://twitter.com/jasonbaldridge/lists/nlp1">list</a> of them.
        </ul>
        <b>Podcasts</b>
        <ul>
          <li>
            AI2's <a href="http://allenai.org/podcast.html">NLP Highlights</a>
          </li>
          <li>
            <a href="https://www.thetalkingmachines.com/">Talking Machines</a>
          </li>
        </ul>
        <b>Courses</b>
        <ul>
          <li>
            Coming soon ... ðŸ™‚
          </li>
        </ul>
</div>

<div id="footer">
      <span>I have used <a href="http://getbootstrap.com"> Bootstrap</a> to build this.</span>
</div>

      <!-- <div id="clustrmaps-widget"></div><script type="text/javascript">var _clustrmaps = {'url' : 'http://cs.cmu.edu/~rajarshd', 'user' : 1136274, 'server' : '2', 'id' : 'clustrmaps-widget', 'version' : 1, 'date' : '2014-03-16', 'lang' : 'en', 'corners' : 'square' };(function (){ var s = document.createElement('script'); s.type = 'text/javascript'; s.async = true; s.src = 'http://www2.clustrmaps.com/counter/map.js'; var x = document.getElementsByTagName('script')[0]; x.parentNode.insertBefore(s, x);})();</script><noscript><a href="http://www2.clustrmaps.com/user/fe7115692"><img src="http://www2.clustrmaps.com/stats/maps-no_clusters/cs.cmu.edu-~rajarshd-thumb.jpg" alt="Locations of visitors to this page" /></a></noscript> -->

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="../../dist/js/bootstrap.min.js"></script>
    <script src="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="../../assets/js/ie10-viewport-bug-workaround.js"></script>
  </body>
</html>
